Data Source: We contacted Sporsho Foundation, a non-profit organization that 
publishes Braille books for visually impaired individuals. They provided us with 
various double-sided Bangla Braille books. They print these books with the help of 
sponsors which then they use to teach blind students. Their generous help really 
meant a lot and contributed highly in the progress and success of our research.

Data Acquisition: We captured high-resolution images of Braille pages using our 
mobile camera. The quality of images was crucial to ensure the Braille dots were 
clearly visible for accurate annotation. We tried to use different angles and lighting 
conditions to introduce variety in the images. These variations helped to capture the 
real life scenario and will help to make the model more robust. 

Annotation: Given the limitations of using Bangla characters in AI models, we 
employed transliteration for labeling the Braille data. This involved converting 
Bangla letters to their phonetic equivalents in English, facilitating the modelâ€™s 
training process. We hand labeled every image manually to their corresponding 
labels using the roboflow annotator. 
